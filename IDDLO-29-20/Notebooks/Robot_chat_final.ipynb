{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dans ce Mini-projet, nous allons créer un Robot-chat relativement simple qui sera utilisé pour répondre aux questions fréquemment posées."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Installation des packages\n",
    "Nous utiliserons simplement pip pour installer ce qui suit:\n",
    "- numpy\n",
    "- nltk\n",
    "- tensorflow\n",
    "- tflearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Données d'entraînement\n",
    "Comme il s'agit d'un simple chat, on va créer un fichier .JSON qui contient les questions et les responses qu'on va utiliser pour le test. on va appeer notre fichier \"intents.json\" dans notre projet\n",
    "#Un extrait du fichier intent.json:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#{\"intents\": [\n",
    "#        {\"tag\": \"greeting\",\n",
    " #        \"patterns\": [\"Hi\", \"How are you\", \"Is anyone there?\", \"Hello\", \"Good day\", \"Whats up\"],\n",
    " #        \"responses\": [\"Hello!\", \"Good to see you again!\", \"Hi there, how can I help?\"],\n",
    "   #      \"context_set\": \"\"\n",
    "    #    },"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce que nous faisons avec le fichier JSON, c'est créer un ensemble de messages que l'utilisateur est susceptible de saisir et de les mapper à un groupe de réponses appropriées. La balise de chaque dictionnaire du fichier indique le groupe auquel appartient également chaque message. Avec ces données, nous formerons un réseau de neurones pour prendre une phrase de mots et la classer comme l'une des balises de notre fichier. Ensuite, nous pouvons simplement prendre une réponse de ces groupes et l'afficher à l'utilisateur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#1- Importation des bibliothèques Chargement de nos données JSON\n",
    "Nous allons commencer par importer quelques modules et charger dans nos données json."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "stemmer = LancasterStemmer()\n",
    "\n",
    "import numpy\n",
    "import tflearn\n",
    "import tensorflow\n",
    "import random\n",
    "import json\n",
    "\n",
    "with open('C:/Users/Mourad/Documents/NLP/intents.json') as file:\n",
    "    data = json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#2- Extraction de données\n",
    "Maintenant on va parcourir nos données JSON et d'extraire les données que nous voulons. Pour chaque motif, nous le transformerons en une liste de mots en utilisant \"nltk.word_tokenize\". Nous ajouterons ensuite chaque modèle dans notre liste docs_words_tag et sa balise associée dans la liste docs_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    words = []\n",
    "    labels = []\n",
    "    docs_words_tok = []\n",
    "    docs_tag = []\n",
    "\n",
    "    for intent in data[\"intents\"]:\n",
    "        for pattern in intent[\"patterns\"]:\n",
    "            wrds = nltk.word_tokenize(pattern)\n",
    "            words.extend(wrds)\n",
    "            docs_words_tok.append(wrds)\n",
    "            docs_tag.append(intent[\"tag\"])\n",
    "\n",
    "        if intent[\"tag\"] not in labels:\n",
    "            labels.append(intent[\"tag\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Racine de mots\n",
    "Nous utiliserons ce processus de racine des mots (Stemmer) pour réduire le vocabulaire de notre modèle et tenter de trouver le sens plus général derrière les phrases comme on vu dans le cours avec le professseur c'est l'un des algorithmes du Natural language processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    words = [stemmer.stem(w.lower()) for w in words if w != \"?\"]\n",
    "    words = sorted(list(set(words)))\n",
    "    labels = sorted(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Bag of words\n",
    "Comme nous le savons, les réseaux de neurones et les algorithmes d'apprentissage automatique nécessitent une entrée numérique. Donc, nous avons besoin d'un moyen de représenter nos phrases avec des nombres et c'est là qu'un sac de mots(bag of words) entre en jeu. Ce que nous allons faire est de représenter chaque phrase avec une liste de la longueur de la quantité de mots dans le vocabulaire de nos modèles. Chaque position dans la liste représentera un mot de notre vocabulaire. Si la position dans la liste est un 1, cela signifie que le mot existe dans notre phrase, s'il s'agit d'un 0, alors le mot n'est pas présent.\n",
    "En plus de formater notre entrée, nous devons formater notre sortie pour qu'elle ait un sens pour le réseau neuronal.Nous créerons des listes de sortie qui correspondent à la longueur de la quantité des lables/tag que nous avons dans notre ensemble de données. Chaque position dans la liste représentera un label/tag distincte, un 1 dans l'une de ces positions indiquera un label/tag est représentée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    training = []\n",
    "    output = []\n",
    "\n",
    "    out_empty = [0 for _ in range(len(labels))]\n",
    "\n",
    "    for idx, doc in enumerate(docs_words_tok):\n",
    "        bag = []\n",
    "        \n",
    "        wrds = [stemmer.stem(w.lower()) for w in doc]\n",
    "\n",
    "        for w in words:\n",
    "            if w in wrds:\n",
    "                bag.append(1)\n",
    "            else:\n",
    "                bag.append(0)\n",
    "\n",
    "        output_row = out_empty[:]\n",
    "        output_row[labels.index(docs_tag[idx])] = 1\n",
    "\n",
    "        training.append(bag)\n",
    "        output.append(output_row)\n",
    "   \n",
    "\n",
    "    training = numpy.array(training)\n",
    "    output = numpy.array(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#3- Développer d'un modèle\n",
    "Maintenant que nous avons prétraité toutes nos données, nous sommes prêts à commencer à créer et à entraîner un modèle. Pour nos besoins, nous utiliserons un réseau de neurones à réaction assez standard avec deux couches cachées. Le but de notre réseau sera de regarder un sac de mots et de donner une classe à laquelle ils appartiennent aussi (une de nos balises du fichier JSON)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#3-1 Nous commencerons par définir l'architecture de notre modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorflow.reset_default_graph()\n",
    "\n",
    "net = tflearn.input_data(shape=[None, len(training[0])])\n",
    "net = tflearn.fully_connected(net, 8)\n",
    "net = tflearn.fully_connected(net, 8)\n",
    "net = tflearn.fully_connected(net, len(output[0]), activation=\"softmax\")\n",
    "net = tflearn.regression(net)\n",
    "\n",
    "modele = tflearn.DNN(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#3-2 Entraînement et sauvegarde du modèle\n",
    "Maintenant nous adapterons nos données au modèle. Le nombre d'epoch que nous avons défini est le nombre de fois où le modèle verra les mêmes informations pendant l'entraînement.\n",
    "Une fois que nous avons terminé la creation du modèle, nous pouvons l'enregistrer dans le fichier modele.tflearn pour une utilisation dans d'autres scripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modele.fit(training, output, n_epoch=1000, batch_size=8, show_metric=True)\n",
    "modele.save(\"modele.tflearn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#4- Test du model(prédictions)\n",
    "Notre processus de génération d'une réponse semblable à ce qui suit:\n",
    "- Obtenez une entrée de l'utilisateur\n",
    "- Convertissez-la en un sac de mots\n",
    "- Obtenez une prédiction du modèle\n",
    "- Trouvez la classe la plus probable\n",
    "- Choisissez une réponse de cette classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#La fonction bag_of_words transformera notre entrée de chaîne en un sac de mots en utilisant notre liste de mots créée\n",
    "\n",
    "def bag_of_words(sentence, words):\n",
    "    bag = [0 for _ in range(len(words))]\n",
    "\n",
    "    s_words = nltk.word_tokenize(sentence)\n",
    "    s_words = [stemmer.stem(word.lower()) for word in s_words]\n",
    "\n",
    "    for sentc in s_words:\n",
    "        for indx, word in enumerate(words):\n",
    "            if word == sentc:\n",
    "                bag[indx] = 1\n",
    "            \n",
    "    return numpy.array(bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#La fonction de chat gérera l'obtention d'une prédiction du modèle et la saisie d'une réponse \n",
    "# appropriée à partir de notre fichier de réponses JSON\n",
    "def chat():\n",
    "    print(\"Commencer la conversation avec le Robot (Tapez stop pour arrêter la concersation)!\")\n",
    "    while True:\n",
    "        entree = input(\"You: \")\n",
    "        if entree.lower() == \"stop\":\n",
    "            break\n",
    "\n",
    "        resultat = model.predict([bag_of_words(entree, words)])\n",
    "        resultat_index = numpy.argmax(resultat)\n",
    "        tag = labels[resultat_index]\n",
    "\n",
    "        for tg in data[\"intents\"]:\n",
    "            if tg['tag'] == tag:\n",
    "                reponses = tg['responses']\n",
    "\n",
    "        print(random.choice(reponses))\n",
    "\n",
    "chat()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
